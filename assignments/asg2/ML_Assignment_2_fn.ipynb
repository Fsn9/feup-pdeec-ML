{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "32620509",
   "metadata": {},
   "source": [
    "# Assignment 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c03c866e",
   "metadata": {},
   "source": [
    "## 1. Generative classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38343624",
   "metadata": {},
   "source": [
    "Consider a classification problem with a target variable $y \\in \\{0, 1\\}$ and input features $\\boldsymbol{x} = (x_1\\; x_2\\; x_3\\; x_4)^T$, where $x_1 \\in \\{0, 1\\}$, $x_2 \\in \\{0, 1\\}$, and $(x_3, x_4) \\in \\mathbb{R}^2$. Further assume that:\n",
    "- $(x_1, x_2)$ is conditionally independent of $(x_3, x_4)$ given $y$;\n",
    "- $x_1$ and $x_2$ are **dependent** given $y$;\n",
    "- $x_3$ and $x_4$ are **dependent** given $y$;\n",
    "- the conditional distributions of $(x_3, x_4)$ given $y$ are Gaussian."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84c2977c",
   "metadata": {},
   "source": [
    "### 1.1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6081895",
   "metadata": {},
   "source": [
    "**a)** Enumerate the parameters of the MAP classifier: $$\\hat{y} = \\text{arg} \\max_{y \\in \\{0, 1\\}} p(y)p(\\boldsymbol{x} \\mid y),$$ and indicate the dimension of each parameter."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fc08105",
   "metadata": {},
   "source": [
    "*YOUR ANSWER HERE* (either typeset or a digitalization of your handwritten answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41873490",
   "metadata": {},
   "source": [
    "**b)** Given a dataset $\\{(\\boldsymbol{x}^{(i)}, y^{(i)})\\}_{i=1}^n$, write the expressions for the maximum likelihood estimates of the parameters enumerated in the previous question."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a2a6e5d",
   "metadata": {},
   "source": [
    "*YOUR ANSWER HERE* (either typeset or a digitalization of your handwritten answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c45eaf5",
   "metadata": {},
   "source": [
    "### 1.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ba5cb63f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries\n",
    "import numpy as np# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9823efc7",
   "metadata": {},
   "source": [
    "Now, you will implement this classifier in Python. The classifier skeleton is provided below in the class `Classifier`. You may implement additional auxiliary methods that you find useful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "12ed9dc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Classifier:\n",
    "    def fit(self, X, y):\n",
    "        '''\n",
    "        Inputs:\n",
    "            X - np.array with shape (num_examples_train, 4)\n",
    "            y - np.array with shape (num_examples_train,)\n",
    "        '''\n",
    "        ###\n",
    "        # YOUR CODE HERE\n",
    "        ###\n",
    "        pass  # remove this line\n",
    "    \n",
    "    def predict(self, X):\n",
    "        '''\n",
    "        Inputs:\n",
    "            X - np.array with shape (num_examples_test, 4)\n",
    "        \n",
    "        Outputs:\n",
    "            ypred - np.array with shape (num_examples_test,)\n",
    "            posteriors - np.array with shape (num_examples_test, 2)\n",
    "        '''\n",
    "        ###\n",
    "        # YOUR CODE HERE\n",
    "        ###\n",
    "        pass  # remove this line"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d2bf886",
   "metadata": {},
   "source": [
    "**N.B.:** In both a) and b), you should avoid for loops as much as possible by using vectorized NumPy operations and broadcasting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fe3261d",
   "metadata": {},
   "source": [
    "**a)** Implement the `fit` method, which receives as input two `np.array`s:\n",
    "- `X`, which contains the 4-dimensional training input examples $\\boldsymbol{x}^{(i)}$, one per row;\n",
    "- `y`, which contains the corresponding training labels $y^{(i)} \\in \\{0,1\\}$, one per row.\n",
    "\n",
    "This method should compute the maximum likelihood estimates of the model parameters and store them as class attributes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "314b8621",
   "metadata": {},
   "source": [
    "**b)** Implement the `predict` method, which receives as input one `np.array`:\n",
    "- `X`, which contains the 4-dimensional examples $\\boldsymbol{x}^{(i)}$ to be classified, one per row.\n",
    "\n",
    "This function should return two `np.array`s:\n",
    "- `ypred`, which should contain the labels predicted for each $\\boldsymbol{x}^{(i)}$, one per row.\n",
    "- `posteriors`, which should contain the posterior probabilities of each class given each $\\boldsymbol{x}^{(i)}$, one per row."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93e3bcac",
   "metadata": {},
   "source": [
    "If you have solved a) and b) correctly, the code below should run without errors and the reported test accuracy should be higher than 80%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b0780e01",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "cannot unpack non-iterable NoneType object",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_15410/2969192505.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m# get the predictions on the test data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mypred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mposteriors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Example 0:'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'  posteriors ='\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mposteriors\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: cannot unpack non-iterable NoneType object"
     ]
    }
   ],
   "source": [
    "# read the data from file\n",
    "data = np.genfromtxt('ex1_data.txt')\n",
    "X, y = data[:, 0:4], data[:, 4].astype(int)\n",
    "\n",
    "# use the first 400 lines for training and the remaining 100 lines for testing\n",
    "Xtrain, ytrain = X[0:400], y[0:400]\n",
    "Xtest, ytest = X[400:], y[400:]\n",
    "\n",
    "# instantiate the classifier and train it\n",
    "classifier = Classifier()\n",
    "classifier.fit(Xtrain, ytrain)\n",
    "\n",
    "# get the predictions on the test data\n",
    "ypred, posteriors = classifier.predict(Xtest)\n",
    "print('Example 0:')\n",
    "print('  posteriors =', posteriors[0])\n",
    "print('  predicted class =', ypred[0])\n",
    "print('  ground-truth class =', ytest[0])\n",
    "print()\n",
    "print('Example 1:')\n",
    "print('  posteriors =', posteriors[1])\n",
    "print('  predicted class =', ypred[1])\n",
    "print('  ground-truth class =', ytest[1])\n",
    "print()\n",
    "print('Example 2:')\n",
    "print('  posteriors =', posteriors[2])\n",
    "print('  predicted class =', ypred[2])\n",
    "print('  ground-truth class =', ytest[2])\n",
    "print()\n",
    "\n",
    "# compute the accuracy on the test set\n",
    "acc = np.mean(ypred == ytest)\n",
    "print(f'Test accuracy = {100.*acc:.1f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68ca18f0",
   "metadata": {},
   "source": [
    "## 2. Logistic regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afc50814",
   "metadata": {},
   "source": [
    "Consider the `heightWeightData.txt` dataset that you have used in the Lab classes. You will use this data to build a Logistic Regression classifier that predicts the sex of an individual given their height and weight."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1201ad8f",
   "metadata": {},
   "source": [
    "**a)** Train a Logistic Regression classifier **using only the first 160 rows** of the dataset as training data. You may use Scikit-Learn (`sklearn.linear_model.LogisticRegression`). **Print the values of the learned parameters.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "596173f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.15294769 -0.10445359]] [34.00288831]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv('heightWeightData.txt', sep = \",\", header = None)\n",
    "X_train, Y_train, X_test, Y_test = data.iloc[:160,1:], data.iloc[:160,0], data.iloc[160:,1:], data.iloc[160:,0]\n",
    "\n",
    "# 1. Creating the model\n",
    "model = LogisticRegression(random_state = 0) \n",
    "\n",
    "# 2. Training the model\n",
    "clf = model.fit(X_train, Y_train) \n",
    "\n",
    "# Printing the coefficients\n",
    "print(clf.coef_, clf.intercept_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2465b356",
   "metadata": {},
   "source": [
    "**b)** Compute the predictions of your model in the remaining 50 rows of the dataset and report the classification accuracy of your model in this test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "984e8b04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions for the last 50 rows: \n",
      "[1 2 1 2 2 2 2 1 2 1 2 2 2 1 2 2 2 2 2 2 1 1 2 2 1 2 2 2 1 2 2 1 2 2 2 2 1\n",
      " 2 2 1 2 2 1 2 1 1 1 1 2 1]\n",
      "The classification accuracy is 92.0%\n"
     ]
    }
   ],
   "source": [
    "preds = clf.predict(X_test)\n",
    "print(f'Predictions for the last 50 rows: \\n{preds}')\n",
    "print(f'The classification accuracy is {100 * model.score(X_test, Y_test)}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "593edb81",
   "metadata": {},
   "source": [
    "**c)** Using the parameter values printed in a), write the equation of the decision boundary of your model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19922303",
   "metadata": {},
   "source": [
    "$Y = W^TX + W_0$,\n",
    "where \n",
    "$W^T=[-0.15294769, -0.10445359]$ \n",
    "and $W_0 = 34.00288831$."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
