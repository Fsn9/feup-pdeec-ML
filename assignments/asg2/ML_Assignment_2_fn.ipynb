{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "32620509",
   "metadata": {},
   "source": [
    "# Assignment 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f1993cc",
   "metadata": {},
   "source": [
    "Student: Francisco Neves (up201404576)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c03c866e",
   "metadata": {},
   "source": [
    "## 1. Generative classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38343624",
   "metadata": {},
   "source": [
    "Consider a classification problem with a target variable $y \\in \\{0, 1\\}$ and input features $\\boldsymbol{x} = (Xy_1\\; x_2\\; x_3\\; x_4)^T$, where $Xy_1 \\in \\{0, 1\\}$, $x_2 \\in \\{0, 1\\}$, and $(x_3, x_4) \\in \\mathbb{R}^2$. Further assume that:\n",
    "- $(Xy_1, x_2)$ is conditionally independent of $(x_3, x_4)$ given $y$;\n",
    "- $Xy_1$ and $x_2$ are **dependent** given $y$;\n",
    "- $x_3$ and $x_4$ are **dependent** given $y$;\n",
    "- the conditional distributions of $(x_3, x_4)$ given $y$ are Gaussian."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84c2977c",
   "metadata": {},
   "source": [
    "### 1.1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6081895",
   "metadata": {},
   "source": [
    "**a)** Enumerate the parameters of the MAP classifier: $$\\hat{y} = \\text{arg} \\max_{y \\in \\{0, 1\\}} p(y)p(\\boldsymbol{x} \\mid y),$$ and indicate the dimension of each parameter."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fc08105",
   "metadata": {},
   "source": [
    "___\n",
    "Before estimating the parameters, by assuming partial independence between $(Xy_1,x_2)$ and $(x_3,x_4)$ the likelihood is described by:\n",
    "$\\begin{equation}\n",
    "p\\left(\\begin{bmatrix}\n",
    "x_{1} \\\\\n",
    "x_{2} \\\\\n",
    "x_{3} \\\\\n",
    "x_{4}\n",
    "\\end{bmatrix}\\middle\\vert y\\right) = \n",
    "p\\left(\\begin{bmatrix}\n",
    "x_{1} \\\\\n",
    "x_{2}\n",
    "\\end{bmatrix}\\middle\\vert y\\right)\n",
    "p\\left(\\begin{bmatrix}\n",
    "x_{3} \\\\\n",
    "x_{4}\n",
    "\\end{bmatrix}\\middle\\vert y\\right).\n",
    "\\end{equation}$\n",
    "\n",
    "Following, we enumerate the different parameters by breaking the problem in three parts (a), (b) and (c).\n",
    "### (a) Parameters for $(Xy_1,x_2)$\n",
    "For the jointed $(Xy_1, x_2)$ features, we have six parameters in total: 3 parameters for $p\\left(\\begin{bmatrix} x_{1} \\\\ x_{2}\\end{bmatrix}\\middle\\vert y = 0 \\right)$ and 3 parameters for $p\\left(\\begin{bmatrix} x_{1} \\\\ x_{2}\\end{bmatrix}\\middle\\vert y = 1\\right)$. Since $Xy_1 \\in \\{0,1\\}$ and $x_2 \\in \\{0,1\\}$ and they are dependent between each other given $y$, one needs to consider all the possible four joint configuration using 2 bits of information, such as $[0,0], [0,1], [1,0], [1,1]$. At least three parameters are enough to estimate for each $p\\left(\\begin{bmatrix} x_{1} \\\\ x_{2}\\end{bmatrix}\\middle\\vert y_i\\right)$, since a fourth is indirectly deduced from the others, such as,\n",
    "$\\begin{equation}\n",
    "  p\\left(\\begin{bmatrix} x_{1} = 0 \\\\ x_{2} = 0\\end{bmatrix}\\middle\\vert y_i\\right) + p\\left(\\begin{bmatrix} x_{1} = 0 \\\\ x_{2} = 1\\end{bmatrix}\\middle\\vert y_i \\right) + p\\left(\\begin{bmatrix} x_{1} = 1 \\\\ x_{2} = 0\\end{bmatrix}\\middle\\vert y_i \\right) + p\\left(\\begin{bmatrix} x_{1} = 1 \\\\ x_{2} = 1\\end{bmatrix}\\middle\\vert y_i \\right) = 1,\n",
    "\\end{equation}$\n",
    "where if $p\\left(\\begin{bmatrix} x_{1} = 1 \\\\ x_{2} = 1\\end{bmatrix}\\middle\\vert y_i \\right)$ is the one not considered, the computation is as follows:\n",
    "$\\begin{equation}\n",
    "p\\left(\\begin{bmatrix} x_{1} = 1 \\\\ x_{2} = 1\\end{bmatrix}\\middle\\vert y_i \\right) = 1 - \\left(p\\left(\\begin{bmatrix} x_{1} = 0 \\\\ x_{2} = 0\\end{bmatrix}\\middle\\vert y_i\\right) + p\\left(\\begin{bmatrix} x_{1} = 0 \\\\ x_{2} = 1\\end{bmatrix}\\middle\\vert y_i \\right) + p\\left(\\begin{bmatrix} x_{1} = 1 \\\\ x_{2} = 0\\end{bmatrix}\\middle\\vert y_i \\right)\\right).\n",
    "\\end{equation}$ \n",
    "Hence, the six parameters are the following:\n",
    "* 3 parameters for $p\\left(\\begin{bmatrix} x_{1} \\\\ x_{2}\\end{bmatrix}\\middle\\vert y = 0 \\right)$: \n",
    "  * $p\\left(\\begin{bmatrix} x_{1} = 0 \\\\ x_{2} = 0\\end{bmatrix}\\middle\\vert y = 0 \\right)$\n",
    "  * $p\\left(\\begin{bmatrix} x_{1} = 0 \\\\ x_{2} = 1\\end{bmatrix}\\middle\\vert y = 0 \\right)$\n",
    "  * $p\\left(\\begin{bmatrix} x_{1} = 1 \\\\ x_{2} = 0\\end{bmatrix}\\middle\\vert y = 0 \\right)$\n",
    "* 3 parameters for $p\\left(\\begin{bmatrix} x_{1} \\\\ x_{2}\\end{bmatrix}\\middle\\vert y = 1 \\right)$:\n",
    "  * $p\\left(\\begin{bmatrix} x_{1} = 0 \\\\ x_{2} = 0\\end{bmatrix}\\middle\\vert y = 1 \\right)$\n",
    "  * $p\\left(\\begin{bmatrix} x_{1} = 0 \\\\ x_{2} = 1\\end{bmatrix}\\middle\\vert y = 1 \\right)$\n",
    "  * $p\\left(\\begin{bmatrix} x_{1} = 1 \\\\ x_{2} = 0\\end{bmatrix}\\middle\\vert y = 1 \\right)$\n",
    "\n",
    "\n",
    "### (b) Parameters for $(x_3, x_4)$\n",
    "For the jointed $(x_3, x_4)$ features, we have ten parameters, as follows: \n",
    "* 4 means: $\\mu_{x_3}=\\begin{bmatrix}\\mu_{x_3}^{y=0} \\\\ \\mu_{x_3}^{y=1}\\end{bmatrix}$ and $\\mu_{x_4}=\\begin{bmatrix}\\mu_{x_4}^{y=0} \\\\ \\mu_{x_4}^{y=1}\\end{bmatrix}$\n",
    "* 6 covariance elements: $\\begin{bmatrix}\n",
    "\\sigma(x_3,x_3)^{2}_{y = 0} & \\sigma(x_3,x_4)^{2}_{y = 0} \\\\\n",
    "\\cdots & \\sigma(x_4,x_4)^{2}_{y = 0}\n",
    "\\end{bmatrix}$ and \n",
    "$ \\begin{bmatrix}\n",
    "\\sigma(x_3,x_3)^{2}_{y = 1} & \\sigma(x_3,x_4)^{2}_{y = 1} \\\\\n",
    "\\cdots & \\sigma(x_4,x_4)^{2}_{y = 1}\n",
    "\\end{bmatrix}$, where $ \\sigma(x_4,x_3)^{2}_{y = 1}$ and  $\\sigma(x_4,x_3)^{2}_{y = 0}$ are omitted, since  $\\sigma(x_3,x_4)^{2}_{y = 0} = \\sigma(x_4,x_3)^{2}_{y = 0}$ and $\\sigma(x_3,x_4)^{2}_{y = 1} = \\sigma(x_4,x_3)^{2}_{y = 1}$ because the covariance matrix is symmetric.\n",
    "\n",
    "### (c) Prior parameters\n",
    "Finally, we have to estimate just one prior, e.g,: $p(y=0)$. Since $p(y=0) = 1 - p(y=1)$, knowing one of them deduces the other.\n",
    "\n",
    "### Number of parameters\n",
    "Hence, in total the model has 17 parameters, such as: 6 parameters from the part (a) plus 10 parameters from the part (b) plus 1 parameter from the part (c).\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41873490",
   "metadata": {},
   "source": [
    "**b)** Given a dataset $\\{(\\boldsymbol{x}^{(i)}, y^{(i)})\\}_{i=1}^n$, write the expressions for the maximum likelihood estimates of the parameters enumerated in the previous question."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a2a6e5d",
   "metadata": {},
   "source": [
    "*YOUR ANSWER HERE* (either typeset or a digitalization of your handwritten answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c45eaf5",
   "metadata": {},
   "source": [
    "### 1.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "ba5cb63f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9823efc7",
   "metadata": {},
   "source": [
    "Now, you will implement this classifier in Python. The classifier skeleton is provided below in the class `Classifier`. You may implement additional auxiliary methods that you find useful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "12ed9dc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Classifier:\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        '''\n",
    "        Inputs:\n",
    "            X - np.array with shape (num_examples_train, 4)\n",
    "            y - np.array with shape (num_examples_train,)\n",
    "        '''\n",
    "        # Class attributes\n",
    "        self.__priors = {}\n",
    "        self.__mus = {}\n",
    "        self.__covs = {}\n",
    "\n",
    "        # Useful variables\n",
    "        Xy = np.concatenate((X, y.reshape(-1,1)), axis = 1)\n",
    "        N = X.shape[0]\n",
    "        Xy_0, Xy_1 = Xy[Xy[:,-1] == 0], Xy[Xy[:,-1] == 1]\n",
    "\n",
    "        x00_0 = Xy_0[(Xy_0[:,0] == 0) & (Xy_0[:,1] == 0)]\n",
    "        x01_0 = Xy_0[(Xy_0[:,0] == 0) & (Xy_0[:,1] == 1)]\n",
    "        x10_0 = Xy_0[(Xy_0[:,0] == 1) & (Xy_0[:,1] == 0)]\n",
    "        x11_0 = Xy_0[(Xy_0[:,0] == 1) & (Xy_0[:,1] == 1)]\n",
    "\n",
    "        x00_1 = Xy_1[(Xy_1[:,0] == 0) & (Xy_1[:,1] == 0)]\n",
    "        x01_1 = Xy_1[(Xy_1[:,0] == 0) & (Xy_1[:,1] == 1)]\n",
    "        x10_1 = Xy_1[(Xy_1[:,0] == 1) & (Xy_1[:,1] == 0)]\n",
    "        x11_1 = Xy_1[(Xy_1[:,0] == 1) & (Xy_1[:,1] == 1)]\n",
    "\n",
    "        x3_0, x3_1, x4_0, x4_1 = Xy_0[:,2].reshape(-1,1), Xy_1[:,2].reshape(-1,1), Xy_0[:,3].reshape(-1,1), Xy_1[:,3].reshape(-1,1)\n",
    "\n",
    "        # (a) Conditional discrete probabilities for x1 and x2\n",
    "        self.__p_x1_x2 = {0: {(0,0): None, (0,1): None, (1,0): None, (1,1): None}, \n",
    "        1: {(0,0): None, (0,1): None, (1,0): None, (1,1): None}}\n",
    "\n",
    "        self.__p_x1_x2[0][(0,0)], self.__p_x1_x2[0][(0,1)], self.__p_x1_x2[0][(1,0)] = x00_0.shape[0] / Xy_0.shape[0], x01_0.shape[0] / Xy_0.shape[0], x10_0.shape[0] / Xy_0.shape[0]\n",
    "        self.__p_x1_x2[0][(1,1)] = 1 - (self.__p_x1_x2[0][(0,0)] + self.__p_x1_x2[0][(0,1)] + self.__p_x1_x2[0][(1,0)])\n",
    "\n",
    "        self.__p_x1_x2[1][(0,0)], self.__p_x1_x2[1][(0,1)], self.__p_x1_x2[1][(1,0)] = x00_1.shape[0] / Xy_1.shape[0], x01_1.shape[0] / Xy_1.shape[0], x10_1.shape[0] / Xy_1.shape[0]\n",
    "        self.__p_x1_x2[1][(1,1)] = 1 - (self.__p_x1_x2[1][(0,0)] + self.__p_x1_x2[1][(0,1)] + self.__p_x1_x2[1][(1,0)])\n",
    "\n",
    "        # (b) Mean and covariance parameters for x3 and x4\n",
    "        self.__mus_x3_x4 = {0: np.array([np.mean(x3_0, axis = 0).item(), np.mean(x4_0, axis = 0).item()]).reshape(-1,1), \n",
    "        1: np.array([np.mean(x3_1, axis = 0).item(), np.mean(x4_1, axis = 0).item()]).reshape(-1,1)}\n",
    "        self.__covs[0] = np.array([\n",
    "            [(np.dot((x3_0 - self.__mus_x3_x4[0][0]).T, x3_0 - self.__mus_x3_x4[0][0]) / N).item(), (np.dot((x3_0 - self.__mus_x3_x4[0][0]).T, x4_0 - self.__mus_x3_x4[0][1]) / N).item()],\n",
    "            [(np.dot((x4_0 - self.__mus_x3_x4[0][1]).T, x3_0 - self.__mus_x3_x4[0][0]) / N).item(), (np.dot((x4_0 - self.__mus_x3_x4[0][1]).T, x4_0 - self.__mus_x3_x4[0][1]) / N).item()]\n",
    "            ])\n",
    "        self.__covs[1] = np.array([\n",
    "            [(np.dot((x3_1 - self.__mus_x3_x4[1][0]).T, x3_1 - self.__mus_x3_x4[1][0]) / N).item(), (np.dot((x3_1 - self.__mus_x3_x4[1][0]).T, x4_1 - self.__mus_x3_x4[1][1]) / N).item()],\n",
    "            [(np.dot((x4_1 - self.__mus_x3_x4[1][1]).T, x3_1 - self.__mus_x3_x4[1][0]) / N).item(), (np.dot((x4_1 - self.__mus_x3_x4[1][1]).T, x4_1 - self.__mus_x3_x4[1][1]) / N).item()]\n",
    "            ])\n",
    "\n",
    "        # (c) Prior parameter\n",
    "        self.__priors[0] = len(y[y == 0]) / y.shape[0]\n",
    "        self.__priors[1] = 1 - self.__priors[0]\n",
    "\n",
    "    # Receives x with shape (num_samples, num_features)\n",
    "    @staticmethod\n",
    "    def multi_variate_gaussian(x, mean, cov_matrix):\n",
    "        k = 1 / ((2 * np.pi) ** (cov_matrix.shape[0] * 0.5)) * np.linalg.det(cov_matrix) ** (-0.5)\n",
    "        z = np.dot(np.dot(-0.5 * (x.T - mean).T, np.linalg.inv(cov_matrix)), (x.T - mean))\n",
    "        return np.diag((k * np.exp(z))).reshape(-1,1)\n",
    "\n",
    "    # Transforms a np.array with shape (num_examples, 2) into a np.array with shape (num_examples, 1) with discrete probabilities\n",
    "    def binomial_discrete_gaussian(self, X, class_idx):\n",
    "        return np.apply_along_axis(func1d = lambda X : self.__p_x1_x2[class_idx][(X[0], X[1])], axis = 1, arr =  X).reshape(-1,1)\n",
    "    \n",
    "    def predict(self, X):\n",
    "        '''\n",
    "        Inputs:\n",
    "            X - np.array with shape (num_examples_test, 4)\n",
    "        \n",
    "        Outputs:\n",
    "            ypred - np.array with shape (num_examples_test,)\n",
    "            posteriors - np.array with shape (num_examples_test, 2)\n",
    "        '''\n",
    "        likelihood_x1_x2_0 = self.binomial_discrete_gaussian(X[:,:2].astype(np.int16), class_idx = 0)\n",
    "        likelihood_x1_x2_1 = self.binomial_discrete_gaussian(X[:,:2].astype(np.int16), class_idx = 1)\n",
    "        likelihood_x3_x4_0 = self.multi_variate_gaussian(X[:,2:], self.__mus_x3_x4[0], self.__covs[0])\n",
    "        likelihood_x3_x4_1 = self.multi_variate_gaussian(X[:,2:], self.__mus_x3_x4[1], self.__covs[1])\n",
    "        posterior0 = likelihood_x1_x2_0 * likelihood_x3_x4_0 * self.__priors[0]\n",
    "        posterior1 = likelihood_x1_x2_1 * likelihood_x3_x4_1 * self.__priors[1]\n",
    "        p_X = posterior0 + posterior1\n",
    "        posteriors = np.concatenate([posterior0 / p_X, posterior1 / p_X], axis = 1)\n",
    "        return np.argmax(posteriors, axis = 1), posteriors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d2bf886",
   "metadata": {},
   "source": [
    "**N.B.:** In both a) and b), you should avoid for loops as much as possible by using vectorized NumPy operations and broadcasting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fe3261d",
   "metadata": {},
   "source": [
    "**a)** Implement the `fit` method, which receives as input two `np.array`s:\n",
    "- `X`, which contains the 4-dimensional training input examples $\\boldsymbol{x}^{(i)}$, one per row;\n",
    "- `y`, which contains the corresponding training labels $y^{(i)} \\in \\{0,1\\}$, one per row.\n",
    "\n",
    "This method should compute the maximum likelihood estimates of the model parameters and store them as class attributes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "314b8621",
   "metadata": {},
   "source": [
    "**b)** Implement the `predict` method, which receives as input one `np.array`:\n",
    "- `X`, which contains the 4-dimensional examples $\\boldsymbol{x}^{(i)}$ to be classified, one per row.\n",
    "\n",
    "This function should return two `np.array`s:\n",
    "- `ypred`, which should contain the labels predicted for each $\\boldsymbol{x}^{(i)}$, one per row.\n",
    "- `posteriors`, which should contain the posterior probabilities of each class given each $\\boldsymbol{x}^{(i)}$, one per row."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93e3bcac",
   "metadata": {},
   "source": [
    "If you have solved a) and b) correctly, the code below should run without errors and the reported test accuracy should be higher than 80%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "b0780e01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "posterior: [[8.09949824e-03]\n",
      " [1.40682073e-02]\n",
      " [4.29680478e-06]\n",
      " [3.57930474e-04]\n",
      " [1.73064906e-02]\n",
      " [1.10284543e-03]\n",
      " [2.27710853e-02]\n",
      " [8.67699822e-04]\n",
      " [1.19922029e-06]\n",
      " [1.67233199e-04]\n",
      " [3.05888530e-02]\n",
      " [3.22842986e-03]\n",
      " [1.14676113e-02]\n",
      " [2.41578758e-03]\n",
      " [1.59325149e-02]\n",
      " [6.24147440e-04]\n",
      " [1.56026560e-08]\n",
      " [2.96230304e-04]\n",
      " [1.84106828e-02]\n",
      " [5.45257094e-03]\n",
      " [1.40081887e-05]\n",
      " [8.87645440e-03]\n",
      " [3.62145773e-04]\n",
      " [3.14324988e-10]\n",
      " [2.87389133e-04]\n",
      " [2.57493431e-03]\n",
      " [2.49887438e-03]\n",
      " [4.79966725e-03]\n",
      " [1.29976881e-02]\n",
      " [4.78563186e-04]\n",
      " [4.95199527e-06]\n",
      " [1.30819884e-03]\n",
      " [9.47987754e-04]\n",
      " [3.15590284e-04]\n",
      " [4.26230674e-04]\n",
      " [6.86660024e-07]\n",
      " [2.69329686e-02]\n",
      " [1.13687760e-02]\n",
      " [7.49219553e-07]\n",
      " [2.93042254e-03]\n",
      " [6.54506413e-04]\n",
      " [1.04816953e-08]\n",
      " [1.32741955e-02]\n",
      " [2.13881512e-06]\n",
      " [5.84465396e-04]\n",
      " [6.73270219e-03]\n",
      " [1.24814408e-09]\n",
      " [2.06709062e-03]\n",
      " [5.86195087e-03]\n",
      " [4.59184946e-05]\n",
      " [1.47100019e-02]\n",
      " [9.20112708e-03]\n",
      " [5.56253341e-03]\n",
      " [3.95398602e-02]\n",
      " [1.20204812e-02]\n",
      " [1.75720090e-02]\n",
      " [2.36402602e-06]\n",
      " [2.14415408e-02]\n",
      " [1.15550534e-02]\n",
      " [2.03624963e-03]\n",
      " [5.56547301e-05]\n",
      " [5.71193111e-03]\n",
      " [3.94298369e-02]\n",
      " [7.42615866e-03]\n",
      " [3.83472421e-03]\n",
      " [5.34307693e-10]\n",
      " [5.83098745e-04]\n",
      " [9.95967750e-06]\n",
      " [2.71671114e-05]\n",
      " [7.25211313e-04]\n",
      " [3.31671072e-04]\n",
      " [1.37758495e-02]\n",
      " [1.21392180e-03]\n",
      " [7.86159673e-05]\n",
      " [1.56509379e-03]\n",
      " [1.63504083e-06]\n",
      " [1.56828171e-02]\n",
      " [4.74776492e-04]\n",
      " [1.01243309e-06]\n",
      " [7.62471229e-03]\n",
      " [9.48131840e-04]\n",
      " [1.95982093e-02]\n",
      " [9.49262576e-04]\n",
      " [1.94149091e-04]\n",
      " [2.47043992e-03]\n",
      " [9.91685812e-05]\n",
      " [8.82954096e-03]\n",
      " [7.08562431e-03]\n",
      " [2.60884603e-02]\n",
      " [3.83721742e-07]\n",
      " [1.43107246e-02]\n",
      " [1.49183693e-04]\n",
      " [1.87952565e-04]\n",
      " [8.12853230e-06]\n",
      " [1.11437989e-11]\n",
      " [7.40371265e-07]\n",
      " [5.81472637e-08]\n",
      " [2.03577013e-03]\n",
      " [1.41171440e-02]\n",
      " [1.34766917e-03]]\n",
      "pX: [[8.09974965e-03]\n",
      " [1.55887277e-02]\n",
      " [3.91101412e-04]\n",
      " [1.10151693e-02]\n",
      " [1.73532385e-02]\n",
      " [1.21594083e-03]\n",
      " [2.30457095e-02]\n",
      " [5.42396207e-03]\n",
      " [9.41178514e-03]\n",
      " [1.67233437e-04]\n",
      " [3.05893282e-02]\n",
      " [3.44821427e-03]\n",
      " [1.14676115e-02]\n",
      " [2.41647225e-03]\n",
      " [1.59325533e-02]\n",
      " [9.03186340e-03]\n",
      " [4.59186919e-03]\n",
      " [2.96657348e-04]\n",
      " [1.84441088e-02]\n",
      " [5.82422995e-03]\n",
      " [4.68307386e-03]\n",
      " [8.87645441e-03]\n",
      " [1.58057322e-03]\n",
      " [9.37776136e-04]\n",
      " [2.87389133e-04]\n",
      " [3.37235940e-03]\n",
      " [2.49888778e-03]\n",
      " [5.26985381e-03]\n",
      " [1.30083239e-02]\n",
      " [7.51911690e-04]\n",
      " [1.88816610e-02]\n",
      " [1.61612687e-03]\n",
      " [6.78783186e-03]\n",
      " [1.59292410e-02]\n",
      " [4.42704615e-04]\n",
      " [1.26728170e-02]\n",
      " [2.69549780e-02]\n",
      " [1.13695935e-02]\n",
      " [6.74568713e-04]\n",
      " [2.94328653e-03]\n",
      " [6.31617080e-03]\n",
      " [1.33180323e-03]\n",
      " [1.32766202e-02]\n",
      " [3.39128414e-03]\n",
      " [6.03469519e-04]\n",
      " [6.73270303e-03]\n",
      " [2.78717104e-03]\n",
      " [2.06709062e-03]\n",
      " [5.92863558e-03]\n",
      " [2.62417449e-02]\n",
      " [1.47100050e-02]\n",
      " [1.03446156e-02]\n",
      " [5.56253341e-03]\n",
      " [3.95399683e-02]\n",
      " [1.20207341e-02]\n",
      " [1.75721353e-02]\n",
      " [1.84927623e-02]\n",
      " [2.14458815e-02]\n",
      " [1.15550534e-02]\n",
      " [2.03666438e-03]\n",
      " [5.56547309e-05]\n",
      " [5.71193541e-03]\n",
      " [3.94369067e-02]\n",
      " [7.42615866e-03]\n",
      " [3.83472421e-03]\n",
      " [1.56397673e-03]\n",
      " [5.83716779e-04]\n",
      " [2.74541009e-02]\n",
      " [9.10368411e-03]\n",
      " [7.25211313e-04]\n",
      " [4.77418252e-04]\n",
      " [1.37777780e-02]\n",
      " [2.45869781e-03]\n",
      " [7.86159673e-05]\n",
      " [1.84768461e-02]\n",
      " [1.36071532e-02]\n",
      " [1.60693294e-02]\n",
      " [9.86759887e-03]\n",
      " [1.28754458e-03]\n",
      " [7.82233014e-03]\n",
      " [5.81133240e-03]\n",
      " [1.96159982e-02]\n",
      " [1.03202413e-02]\n",
      " [1.99625800e-04]\n",
      " [2.48379132e-03]\n",
      " [7.60568296e-03]\n",
      " [8.83168025e-03]\n",
      " [7.08842882e-03]\n",
      " [2.61042287e-02]\n",
      " [5.98682001e-03]\n",
      " [1.56169910e-02]\n",
      " [1.68795001e-02]\n",
      " [1.96072099e-04]\n",
      " [1.55048558e-02]\n",
      " [2.54893210e-04]\n",
      " [1.63556925e-02]\n",
      " [1.59784447e-03]\n",
      " [3.50204944e-03]\n",
      " [1.41182099e-02]\n",
      " [1.34766967e-03]]\n",
      "normalized: [[9.99968961e-01]\n",
      " [9.02460261e-01]\n",
      " [1.09864210e-02]\n",
      " [3.24943234e-02]\n",
      " [9.97306095e-01]\n",
      " [9.06989382e-01]\n",
      " [9.88083502e-01]\n",
      " [1.59975275e-01]\n",
      " [1.27416879e-04]\n",
      " [9.99998580e-01]\n",
      " [9.99984466e-01]\n",
      " [9.36261382e-01]\n",
      " [9.99999977e-01]\n",
      " [9.99716665e-01]\n",
      " [9.99997590e-01]\n",
      " [6.91050576e-02]\n",
      " [3.39788774e-06]\n",
      " [9.98560482e-01]\n",
      " [9.98187715e-01]\n",
      " [9.36187442e-01]\n",
      " [2.99123805e-03]\n",
      " [9.99999998e-01]\n",
      " [2.29123061e-01]\n",
      " [3.35181261e-07]\n",
      " [1.00000000e+00]\n",
      " [7.63540893e-01]\n",
      " [9.99994635e-01]\n",
      " [9.10778062e-01]\n",
      " [9.99182379e-01]\n",
      " [6.36461956e-01]\n",
      " [2.62264812e-04]\n",
      " [8.09465438e-01]\n",
      " [1.39659876e-01]\n",
      " [1.98120101e-02]\n",
      " [9.62787963e-01]\n",
      " [5.41836928e-05]\n",
      " [9.99183475e-01]\n",
      " [9.99928101e-01]\n",
      " [1.11066454e-03]\n",
      " [9.95629378e-01]\n",
      " [1.03623926e-01]\n",
      " [7.87030322e-06]\n",
      " [9.99817367e-01]\n",
      " [6.30680012e-04]\n",
      " [9.68508562e-01]\n",
      " [9.99999875e-01]\n",
      " [4.47817539e-07]\n",
      " [1.00000000e+00]\n",
      " [9.88752099e-01]\n",
      " [1.74982627e-03]\n",
      " [9.99999791e-01]\n",
      " [8.89460515e-01]\n",
      " [9.99999999e-01]\n",
      " [9.99997267e-01]\n",
      " [9.99978964e-01]\n",
      " [9.99992810e-01]\n",
      " [1.27835203e-04]\n",
      " [9.99797596e-01]\n",
      " [1.00000000e+00]\n",
      " [9.99796356e-01]\n",
      " [9.99999985e-01]\n",
      " [9.99999247e-01]\n",
      " [9.99820731e-01]\n",
      " [9.99999999e-01]\n",
      " [1.00000000e+00]\n",
      " [3.41634042e-07]\n",
      " [9.98941209e-01]\n",
      " [3.62775585e-04]\n",
      " [2.98418871e-03]\n",
      " [1.00000000e+00]\n",
      " [6.94718039e-01]\n",
      " [9.99860030e-01]\n",
      " [4.93725499e-01]\n",
      " [1.00000000e+00]\n",
      " [8.47056786e-02]\n",
      " [1.20160389e-04]\n",
      " [9.75947199e-01]\n",
      " [4.81146932e-02]\n",
      " [7.86328568e-04]\n",
      " [9.74736703e-01]\n",
      " [1.63152230e-01]\n",
      " [9.99093146e-01]\n",
      " [9.19806568e-02]\n",
      " [9.72565120e-01]\n",
      " [9.94624587e-01]\n",
      " [1.30387477e-02]\n",
      " [9.99757771e-01]\n",
      " [9.99604354e-01]\n",
      " [9.99395945e-01]\n",
      " [6.40944176e-05]\n",
      " [9.16356078e-01]\n",
      " [8.83815823e-03]\n",
      " [9.58589039e-01]\n",
      " [5.24257200e-04]\n",
      " [4.37194811e-08]\n",
      " [4.52668858e-05]\n",
      " [3.63910661e-05]\n",
      " [5.81308220e-01]\n",
      " [9.99924499e-01]\n",
      " [9.99999633e-01]]\n",
      "Example 0:\n",
      "  posteriors = [9.99968961e-01 3.10386558e-05]\n",
      "  predicted class = 0\n",
      "  ground-truth class = 0\n",
      "\n",
      "Example 1:\n",
      "  posteriors = [0.90246026 0.09753974]\n",
      "  predicted class = 0\n",
      "  ground-truth class = 1\n",
      "\n",
      "Example 2:\n",
      "  posteriors = [0.01098642 0.98901358]\n",
      "  predicted class = 1\n",
      "  ground-truth class = 1\n",
      "\n",
      "Test accuracy = 90.0%\n"
     ]
    }
   ],
   "source": [
    "# read the data from file\n",
    "data = np.genfromtxt('ex1_data.txt')\n",
    "X, y = data[:, 0:4], data[:, 4].astype(int)\n",
    "\n",
    "# use the first 400 lines for training and the remaining 100 lines for testing\n",
    "Xtrain, ytrain = X[0:400], y[0:400]\n",
    "Xtest, ytest = X[400:], y[400:]\n",
    "\n",
    "# instantiate the classifier and train it\n",
    "classifier = Classifier()\n",
    "classifier.fit(Xtrain, ytrain)\n",
    "\n",
    "# get the predictions on the test data\n",
    "ypred, posteriors = classifier.predict(Xtest)\n",
    "print('Example 0:')\n",
    "print('  posteriors =', posteriors[0])\n",
    "print('  predicted class =', ypred[0])\n",
    "print('  ground-truth class =', ytest[0])\n",
    "print()\n",
    "print('Example 1:')\n",
    "print('  posteriors =', posteriors[1])\n",
    "print('  predicted class =', ypred[1])\n",
    "print('  ground-truth class =', ytest[1])\n",
    "print()\n",
    "print('Example 2:')\n",
    "print('  posteriors =', posteriors[2])\n",
    "print('  predicted class =', ypred[2])\n",
    "print('  ground-truth class =', ytest[2])\n",
    "print()\n",
    "\n",
    "# compute the accuracy on the test set\n",
    "acc = np.mean(ypred == ytest)\n",
    "print(f'Test accuracy = {100.*acc:.1f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68ca18f0",
   "metadata": {},
   "source": [
    "## 2. Logistic regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afc50814",
   "metadata": {},
   "source": [
    "Consider the `heightWeightData.txt` dataset that you have used in the Lab classes. You will use this data to build a Logistic Regression classifier that predicts the sex of an individual given their height and weight."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1201ad8f",
   "metadata": {},
   "source": [
    "**a)** Train a Logistic Regression classifier **using only the first 160 rows** of the dataset as training data. You may use Scikit-Learn (`sklearn.linear_model.LogisticRegression`). **Print the values of the learned parameters.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "596173f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.15294769 -0.10445359]] [34.00288831]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv('heightWeightData.txt', sep = \",\", header = None)\n",
    "X_train, Y_train, X_test, Y_test = data.iloc[:160,1:], data.iloc[:160,0], data.iloc[160:,1:], data.iloc[160:,0]\n",
    "\n",
    "# 1. Creating the model\n",
    "model = LogisticRegression(random_state = 0) \n",
    "\n",
    "# 2. Training the model\n",
    "clf = model.fit(X_train, Y_train) \n",
    "\n",
    "# Printing the coefficients\n",
    "print(clf.coef_, clf.intercept_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2465b356",
   "metadata": {},
   "source": [
    "**b)** Compute the predictions of your model in the remaining 50 rows of the dataset and report the classification accuracy of your model in this test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "984e8b04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions for the last 50 rows: \n",
      "[1 2 1 2 2 2 2 1 2 1 2 2 2 1 2 2 2 2 2 2 1 1 2 2 1 2 2 2 1 2 2 1 2 2 2 2 1\n",
      " 2 2 1 2 2 1 2 1 1 1 1 2 1]\n",
      "The classification accuracy is 92.0%\n"
     ]
    }
   ],
   "source": [
    "preds = clf.predict(X_test)\n",
    "print(f'Predictions for the last 50 rows: \\n{preds}')\n",
    "print(f'The classification accuracy is {100 * model.score(X_test, Y_test)}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "593edb81",
   "metadata": {},
   "source": [
    "**c)** Using the parameter values printed in a), write the equation of the decision boundary of your model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19922303",
   "metadata": {},
   "source": [
    "$Y = W^TX + W_0$,\n",
    "where \n",
    "$W^T=[-0.15294769, -0.10445359]$ \n",
    "and $W_0 = 34.00288831$."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
