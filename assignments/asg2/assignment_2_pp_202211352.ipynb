{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "32620509",
   "metadata": {},
   "source": [
    "# Assignment 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0fc9349",
   "metadata": {},
   "source": [
    "$\\color{blue}{Name\\text{ }Student\\text{ }1:} \\text{João Dionísio (202111348)}$\n",
    "\n",
    "$\\color{blue}{Name\\text{ }Student\\text{ }2:} \\text{Pedro Pereira (202111352)}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c03c866e",
   "metadata": {},
   "source": [
    "## 1. Generative classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38343624",
   "metadata": {},
   "source": [
    "Consider a classification problem with a target variable $y \\in \\{0, 1\\}$ and input features $\\boldsymbol{x} = (x_1\\; x_2\\; x_3\\; x_4)^T$, where $x_1 \\in \\{0, 1\\}$, $x_2 \\in \\{0, 1\\}$, and $(x_3, x_4) \\in \\mathbb{R}^2$. Further assume that:\n",
    "- $(x_1, x_2)$ is conditionally independent of $(x_3, x_4)$ given $y$;\n",
    "- $x_1$ and $x_2$ are **dependent** given $y$;\n",
    "- $x_3$ and $x_4$ are **dependent** given $y$;\n",
    "- the conditional distributions of $(x_3, x_4)$ given $y$ are Gaussian."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84c2977c",
   "metadata": {},
   "source": [
    "### 1.1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6081895",
   "metadata": {},
   "source": [
    "**a)** Enumerate the parameters of the MAP classifier: $$\\hat{y} = \\text{arg} \\max_{y \\in \\{0, 1\\}} p(y)p(\\boldsymbol{x} \\mid y),$$ and indicate the dimension of each parameter."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fc08105",
   "metadata": {},
   "source": [
    "$\\textbf{Resolution}$\n",
    "\n",
    "Since ($x_1, x_2$) is conditionally independent of ($x_3, x_4$) given $\\textit{y}$, assuming Naive Bayes, the class-conditional density $p(\\boldsymbol{x} | y)$ can be rewritten as:\n",
    "\n",
    "$$\n",
    "p(\\boldsymbol{x} | y) = p(x_1, x_2 | y) \\cdot p(x_3, x_4 | y),\n",
    "$$\n",
    "\n",
    "and the MAP classifier becomes:\n",
    "\n",
    "$$\n",
    "\\hat{y} = \\arg \\max_{y \\in \\{0, 1\\}} p(y) \\cdot p(x_1, x_2 | y) \\cdot p(x_3, x_4 | y).\n",
    "$$\n",
    "\n",
    "To determine $p(y)$, we only need to estimate $p(y=1)$ since $p(y=0)+p(y=1)=1$. Thus, since $p(y) \\sim \\mathcal{B}(p)$, the only parameter necessary to estimate is the probability of success $p(y=1)$, which is a scalar.\n",
    "\n",
    "For $p(x_1, x_2 | y)$, we need to determine the probabilities for each combination of $x_1$ and $x_2$ ($2^2$), once for $y=0$ and once for $y=1$ ($2^2 * 2$). Since the sum of these combinations needs to equal 1 for each $y=0$ and $y=1$, in reality, we only need to estimate 6 parameters ($(2^2 -1) * 2$). We can think of it as a multinomial distribution, where we need to obtain the probability of each combination given $y$, which are scalars.\n",
    "\n",
    "Finally, in the case of $p(x_3, x_4 | y)$, we need to determine the same number of parameters as for $p(x_1, x_2 | y)$. However, thinking of $p(x_3, x_4 | y)$ as a multivariate Gaussian, $p(x_1, x_2 | y) \\sim \\mathcal{N}(\\mu, \\Sigma)$, we need to estimate the average of each feature, $\\mu \\in \\mathbb{R}^{2}$, and the covariance matrix, $\\Sigma \\in \\mathbb{R}^{2\\times 2}$, which has dimension 2x2. Since $\\Sigma$ is symmetrical we only need to estimate 3 parameters ($\\Sigma_{11}$, $\\Sigma_{22}$ and $\\Sigma_{12}=\\Sigma_{21}$). These parameters need to be estimated for each class, $y = 0$ and $y = 1$.\n",
    "\n",
    "In total we need to estimate 17 parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41873490",
   "metadata": {},
   "source": [
    "**b)** Given a dataset $\\{(\\boldsymbol{x}^{(i)}, y^{(i)})\\}_{i=1}^n$, write the expressions for the maximum likelihood estimates of the parameters enumerated in the previous question."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a2a6e5d",
   "metadata": {},
   "source": [
    "$\\textbf{Resolution}$\n",
    "\n",
    "$\\textit{MLE for binomial distribution:}$\n",
    "\n",
    "Considering $n$ data points, the log likelihood function can be written as:\n",
    "\n",
    "$$\n",
    "LL(p) = \\sum_{i=1}^{n} \\left[ log \\left( p^{y_i} (1-p)^{1-y_i} \\right) \\right] = \\\\\n",
    "\\sum_{i=1}^{n} \\left[ y_i log (p) + (1 - y_i) log (1-p) \\right] = \\\\\n",
    "Y log (p) + (n - Y) log (1-p) \\quad \\quad \\text{where } Y =  \\sum_{i=1}^{n} y_i\n",
    "$$\n",
    "\n",
    "To maximize the log likelihood, we take its derivative as a function of $p$ and set it to zero:\n",
    "\n",
    "$$\n",
    "\\frac{\\partial LL(p)}{\\partial p} = Y \\frac{1}{p} + (n - Y) \\frac{-1}{n-p} = 0 \\Rightarrow \\\\\n",
    "p = \\frac{Y}{n}\n",
    "$$\n",
    "\n",
    "This is the sample mean.\n",
    "\n",
    "$\\textit{MLE for multinomial distribution:}$\n",
    "\n",
    "We can think of $p(x_1, x_2 | y)$ as two multinomial distributions where there are four possible scenarios correspondent to the combinations between $x_1$ and $x_2$, one for each class $y$. Therefore we can take once again the log likelihood function of a multinomial distribution as:\n",
    "\n",
    "$$\n",
    "LL(p) = log \\left[ n! \\left( \\prod_{i=1}^{m} \\frac{p_i^{x_i}}{x_i!} \\right) \\right] = \\\\\n",
    "log(n!) + \\sum_{i=1}^{m} x_i log(p_i) - \\sum_{i=1}^{m} x_i log(x_i!)\n",
    "$$\n",
    "\n",
    "where $m$ is the number of combinations and $n$ is the number of data points in the dataset given the class. Before differentiating the previous equation, we need to introduce the constrain that the sum of all the probabities $p_i$ given the class sum up to 1:\n",
    "\n",
    "$$\n",
    "\\sum_{i=1}^{m} p_i = 1\n",
    "$$\n",
    "\n",
    "We can now constraint our likelihood function considering the lagrangian:\n",
    "\n",
    "$$\n",
    "\\mathcal{L}(p) = LL(p) + \\lambda (1 - \\sum_{i=1}^{m} p_i)\n",
    "$$\n",
    "\n",
    "Differentiating the lagrangian with respect to $p_i$:\n",
    "\n",
    "$$\n",
    "\\frac{\\partial \\mathcal{L}(p)}{\\partial p} = \\frac{\\partial LL(p)}{\\partial p_i} - \\lambda = \\frac{x_i}{p_i} - \\lambda\n",
    "$$\n",
    "\n",
    "Setting the lagrangian to zero:\n",
    "\n",
    "$$\n",
    "p_i = \\frac{x_i}{\\lambda}\n",
    "$$\n",
    "\n",
    "To solve for $\\lambda$, we sum both sides and use of our initial constraint:\n",
    "\n",
    "$$\n",
    "\\sum_{i=1}^{m} p_i = \\sum_{i=1}^{m} \\frac{x_i}{\\lambda} \\Rightarrow 1 = \\frac{1}{\\lambda} \\sum_{i=1}^{m} x_i \\Rightarrow \\\\\n",
    "1 = \\frac{1}{\\lambda} n \\Rightarrow \\lambda = n\n",
    "$$\n",
    "\n",
    "giving the MLE for $p_i$:\n",
    "\n",
    "$$\n",
    "p_i = \\frac{x_i}{n}\n",
    "$$\n",
    "\n",
    "So, for example, the probability of $x_1 = 0$ and $x_2 = 0$ knowing that $y = 0$ ($p(x_1=0, x_2=0 | y=0)$) is given by:\n",
    "\n",
    "$$\n",
    "p(x_1=0, x_2=0 | y=0) = \\frac{\\text{number of data points where } x_1 = 0, x_2 = 0 \\text{ and } y = 0}{\\text{number of data points where } y = 0}\n",
    "$$\n",
    "\n",
    "$\\textit{MLE for multivariate Gaussian distribution:}$\n",
    "\n",
    "The log likelihood function of a multivariate gaussian can be written as:\n",
    "\n",
    "$$\n",
    "LL(\\mu, \\Sigma) = - \\frac{N}{2} log(|\\Sigma|) - \\frac{1}{2} \\sum_{i=1}{N} (x_i - \\mu)^T \\Sigma^{-1} (x_i - \\mu)\n",
    "$$\n",
    "\n",
    "Taking the derivative with respect to $\\mu$ and setting to zero, we obtain:\n",
    "\n",
    "$$\n",
    "\\hat{\\mu} = \\frac{1}{N} \\sum_{i=1}^{N} x_i\n",
    "$$\n",
    "\n",
    "while, for $\\Sigma$ we obtain:\n",
    "\n",
    "$$\n",
    "\\hat{\\Sigma} = \\frac{1}{N} \\sum_n (x_n - \\hat{\\mu}) (x_n - \\hat{\\mu})^T\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c45eaf5",
   "metadata": {},
   "source": [
    "### 1.2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9823efc7",
   "metadata": {},
   "source": [
    "Now, you will implement this classifier in Python. The classifier skeleton is provided below in the class `Classifier`. You may implement additional auxiliary methods that you find useful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "67d1a9a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the necessary libraries #\n",
    "import numpy as np\n",
    "from math import pi, exp\n",
    "\n",
    "class Classifier:\n",
    "    def fit(self, X, y):\n",
    "        '''\n",
    "        Inputs:\n",
    "            X - np.array with shape (num_examples_train, 4)\n",
    "            y - np.array with shape (num_examples_train,)\n",
    "        '''\n",
    "        # Function to compute the MLE estimates of a Multivariate Gaussian #\n",
    "        def mv_gauss(X):\n",
    "            # Means of the features #\n",
    "            x_mean = np.mean(X, axis = 0)\n",
    "            \n",
    "            # Covariance matrix of the features #\n",
    "            x_cov = np.cov(X, rowvar=False)\n",
    "            \n",
    "            # Return the means and covariance matrix #\n",
    "            return x_mean, x_cov\n",
    "\n",
    "        # Function to compute the MLE estimates of the Multinomial Distribution #\n",
    "        def multinomial(X):\n",
    "            # Possible combinations between features #\n",
    "            p = {(0,0): float(0),\n",
    "                 (0,1): float(0),\n",
    "                 (1,1): float(0),\n",
    "                 (1,0): float(0),}\n",
    "\n",
    "            # Split the dataset #\n",
    "            X0x = X[X[:,0] == 0]\n",
    "            X1x = X[X[:,0] == 1]\n",
    "            \n",
    "            # Probabilities for the possible combinations between features #\n",
    "            p[(0,0)] = X0x[X0x[:,1]== 0].shape[0] / X.shape[0]\n",
    "            p[(0,1)] = X0x[X0x[:,1]== 1].shape[0] / X.shape[0]\n",
    "            p[(1,1)] = X1x[X1x[:,1]== 1].shape[0] / X.shape[0]\n",
    "            p[(1,0)] = 1 - (p[(0,0)] + p[(0,1)] + p[(1,1)])\n",
    "            \n",
    "            # Return the dictionary of features #\n",
    "            return p\n",
    "\n",
    "        # Split the labels dataset into two classes #\n",
    "        y0 = y[y == 0]  # Dataset where y = 0\n",
    "        y1 = y[y == 1]  # Dataset where y = 1\n",
    "        \n",
    "        # Class prior probabilities #\n",
    "        self.prior_y0 = y0.shape[0] / y.shape[0]\n",
    "        self.prior_y1 = y1.shape[0] / y.shape[0]\n",
    "        \n",
    "        # Split the features dataset into two classes # \n",
    "        X_y0 = X[y==0]\n",
    "        X_y1 = X[y==1]\n",
    "        \n",
    "        # MLE estimates for the Multivariate Gaussian features #\n",
    "        self.y0x34_mean, self.y0x34_cov = mv_gauss(X_y0[:,2:4])\n",
    "        self.y1x34_mean, self.y1x34_cov = mv_gauss(X_y1[:,2:4])\n",
    "\n",
    "        # MLE estimates for the Multinomial features #\n",
    "        self.p0 = multinomial(X_y0[:,0:2])\n",
    "        self.p1 = multinomial(X_y1[:,0:2])\n",
    "\n",
    "    def predict(self, X):\n",
    "        '''\n",
    "        Inputs:\n",
    "            X - np.array with shape (num_examples_test, 4)\n",
    "        \n",
    "        Outputs:\n",
    "            ypred - np.array with shape (num_examples_test,)\n",
    "            posteriors - np.array with shape (num_examples_test, 2)\n",
    "        '''\n",
    "        \n",
    "        # Function to compute the probability density function of a Multivariate Gaussian #\n",
    "        def Multivariate_Gaussian(X, mean, cov):\n",
    "            # Compute the probability #\n",
    "            const = 2*pi**(-1)*np.linalg.det(cov)**(-1/2)\n",
    "            exp_ = exp(-1/2*(np.dot(np.dot((X-mean).T, np.linalg.inv(cov)),(X-mean))))\n",
    "            prob = const*exp_\n",
    "            \n",
    "            # Return the probability #\n",
    "            return prob\n",
    "\n",
    "        # Initialize the output variables #\n",
    "        posteriors = np.matrix([None,None])\n",
    "        ypred = np.zeros((X.shape[0]))\n",
    "        \n",
    "        # Perfom the predictions for each point in the test dataset #\n",
    "        for i in range(0, X.shape[0]):\n",
    "            # Class conditionals for features x1 and x2 #\n",
    "            mn_pred_0 =  self.p0[(X[i,0],X[i,1])]\n",
    "            mn_pred_1 =  self.p1[(X[i,0],X[i,1])]\n",
    "            \n",
    "            # Class conditionals for features x3 and x4 #\n",
    "            g_pred_0 = Multivariate_Gaussian(X[i,2:4], self.y0x34_mean, self.y0x34_cov)\n",
    "            g_pred_1 = Multivariate_Gaussian(X[i,2:4], self.y1x34_mean, self.y1x34_cov)\n",
    "            \n",
    "            # Determine posteriors #\n",
    "            pred_0 = mn_pred_0 * g_pred_0 * self.prior_y0\n",
    "            pred_1 = mn_pred_1 * g_pred_1 * self.prior_y1\n",
    "            \n",
    "            # Normalize the posteriors #\n",
    "            sum_ = pred_0 + pred_1\n",
    "            pred_0 = pred_0 / sum_\n",
    "            pred_1 = pred_1 / sum_\n",
    "\n",
    "            # Save the posteriors #\n",
    "            posteriors = np.concatenate((posteriors, np.matrix([pred_0, pred_1])),axis=0)\n",
    "            \n",
    "            # Make predictions #\n",
    "            if pred_0 > pred_1:\n",
    "                ypred[i] = 0\n",
    "            elif pred_0 < pred_1:\n",
    "                ypred[i] = 1\n",
    "            else:\n",
    "                # If the posteriors are equal, choose ramdomly #\n",
    "                ypred[i] = np.random.randint(0,1)\n",
    "                \n",
    "        posteriors = np.delete(posteriors,[0],axis=0)\n",
    "        \n",
    "        # Return the outputs #\n",
    "        return ypred, posteriors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d2bf886",
   "metadata": {},
   "source": [
    "**N.B.:** In both a) and b), you should avoid for loops as much as possible by using vectorized NumPy operations and broadcasting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fe3261d",
   "metadata": {},
   "source": [
    "**a)** Implement the `fit` method, which receives as input two `np.array`s:\n",
    "- `X`, which contains the 4-dimensional training input examples $\\boldsymbol{x}^{(i)}$, one per row;\n",
    "- `y`, which contains the corresponding training labels $y^{(i)} \\in \\{0,1\\}$, one per row.\n",
    "\n",
    "This method should compute the maximum likelihood estimates of the model parameters and store them as class attributes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "314b8621",
   "metadata": {},
   "source": [
    "**b)** Implement the `predict` method, which receives as input one `np.array`:\n",
    "- `X`, which contains the 4-dimensional examples $\\boldsymbol{x}^{(i)}$ to be classified, one per row.\n",
    "\n",
    "This function should return two `np.array`s:\n",
    "- `ypred`, which should contain the labels predicted for each $\\boldsymbol{x}^{(i)}$, one per row.\n",
    "- `posteriors`, which should contain the posterior probabilities of each class given each $\\boldsymbol{x}^{(i)}$, one per row."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93e3bcac",
   "metadata": {},
   "source": [
    "If you have solved a) and b) correctly, the code below should run without errors and the reported test accuracy should be higher than 80%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b0780e01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example 0:\n",
      "  posteriors = [[0.9821538212446846 0.01784617875531535]]\n",
      "  predicted class = 0.0\n",
      "  ground-truth class = 0\n",
      "\n",
      "Example 1:\n",
      "  posteriors = [[0.7679840555476175 0.23201594445238263]]\n",
      "  predicted class = 0.0\n",
      "  ground-truth class = 1\n",
      "\n",
      "Example 2:\n",
      "  posteriors = [[0.03193051652512521 0.9680694834748746]]\n",
      "  predicted class = 1.0\n",
      "  ground-truth class = 1\n",
      "\n",
      "Test accuracy = 92.0%\n"
     ]
    }
   ],
   "source": [
    "# read the data from file\n",
    "data = np.genfromtxt('ex1_data.txt')\n",
    "X, y = data[:, 0:4], data[:, 4].astype(int)\n",
    "\n",
    "# use the first 400 lines for training and the remaining 100 lines for testing\n",
    "Xtrain, ytrain = X[0:400], y[0:400]\n",
    "Xtest, ytest = X[400:], y[400:]\n",
    "\n",
    "# instantiate the classifier and train it\n",
    "classifier = Classifier()\n",
    "classifier.fit(Xtrain, ytrain)\n",
    "\n",
    "# get the predictions on the test data\n",
    "ypred, posteriors = classifier.predict(Xtest)\n",
    "print('Example 0:')\n",
    "print('  posteriors =', posteriors[0])\n",
    "print('  predicted class =', ypred[0])\n",
    "print('  ground-truth class =', ytest[0])\n",
    "print()\n",
    "print('Example 1:')\n",
    "print('  posteriors =', posteriors[1])\n",
    "print('  predicted class =', ypred[1])\n",
    "print('  ground-truth class =', ytest[1])\n",
    "print()\n",
    "print('Example 2:')\n",
    "print('  posteriors =', posteriors[2])\n",
    "print('  predicted class =', ypred[2])\n",
    "print('  ground-truth class =', ytest[2])\n",
    "print()\n",
    "\n",
    "# compute the accuracy on the test set\n",
    "acc = np.mean(ypred == ytest)\n",
    "print(f'Test accuracy = {100.*acc:.1f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68ca18f0",
   "metadata": {},
   "source": [
    "## 2. Logistic regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afc50814",
   "metadata": {},
   "source": [
    "Consider the `heightWeightData.txt` dataset that you have used in the Lab classes. You will use this data to build a Logistic Regression classifier that predicts the sex of an individual given their height and weight."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1201ad8f",
   "metadata": {},
   "source": [
    "**a)** Train a Logistic Regression classifier **using only the first 160 rows** of the dataset as training data. You may use Scikit-Learn (`sklearn.linear_model.LogisticRegression`). **Print the values of the learned parameters.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "596173f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interception (w0):\n",
      " [34.00288831]\n",
      "Coefficients (w1 and w2):\n",
      " [[-0.15294769 -0.10445359]]\n"
     ]
    }
   ],
   "source": [
    "# Import the necessary libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import linear_model\n",
    "\n",
    "# Read the data from the file and split the features from the labels #\n",
    "data = np.genfromtxt('heightWeightData.txt', delimiter=',')\n",
    "y, X = data[:, 0].astype(int), data[:, 1:3]\n",
    "\n",
    "# Split the data into the training and testing datasets #\n",
    "Xtrain, ytrain = X[0:160], y[0:160]\n",
    "Xtest, ytest = X[160:], y[160:]\n",
    "\n",
    "# Apply a Logistic Regression to the training dataset #\n",
    "LogReg = linear_model.LogisticRegression()\n",
    "LogReg.fit(Xtrain, ytrain)\n",
    "\n",
    "# Learned parameters #\n",
    "print('Interception (w0):\\n', LogReg.intercept_)\n",
    "print('Coefficients (w1 and w2):\\n', LogReg.coef_)\n",
    "\n",
    "w0 = LogReg.intercept_\n",
    "w1 = LogReg.coef_[:, 0]\n",
    "w2 = LogReg.coef_[:, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2465b356",
   "metadata": {},
   "source": [
    "**b)** Compute the predictions of your model in the remaining 50 rows of the dataset and report the classification accuracy of your model in this test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "984e8b04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy = 92.0%\n"
     ]
    }
   ],
   "source": [
    "# Make predictions #\n",
    "predictions = LogReg.predict(Xtest)\n",
    "\n",
    "# Compute the accuracy of the model #\n",
    "score = LogReg.score(Xtest, ytest)\n",
    "print(f'Test accuracy = {100.*score:.1f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "593edb81",
   "metadata": {},
   "source": [
    "**c)** Using the parameter values printed in a), write the equation of the decision boundary of your model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "291b064f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision boundary equation:\n",
      " y =  [34.00288831]  +  [-0.15294769] * X_1 +  [-0.10445359] * X_2\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Decision boundary equation #\n",
    "print('Decision boundary equation:\\n', 'y = ', w0, ' + ', w1, '* X_1 + ', w2, '* X_2')\n",
    "\n",
    "# Split the training data into classes #\n",
    "Xtrain1 = Xtrain[ytrain == 1]\n",
    "Xtrain2 = Xtrain[ytrain == 2]\n",
    "\n",
    "# -> Plotting the decision boundary <- #\n",
    "# Find the maximum and minimum values for each feature of the training dataset #\n",
    "x_min, x_max = Xtrain[:, 0].min() - 10, Xtrain[:, 0].max() + 10\n",
    "y_min, y_max = Xtrain[:, 1].min() - 10, Xtrain[:, 1].max() + 10\n",
    "\n",
    "# Create a meshgrid for the dataset #\n",
    "xx_train, yy_train = np.meshgrid(np.arange(x_min, x_max, 0.1),\n",
    "                                 np.arange(y_min, y_max, 0.1))\n",
    "\n",
    "# Create the boundary #\n",
    "Z_train = LogReg.predict(np.c_[xx_train.ravel(), yy_train.ravel()])\n",
    "Z_train = Z_train.reshape(xx_train.shape)\n",
    "\n",
    "# Plot the decision boundary #\n",
    "plt.contourf(xx_train, yy_train, Z_train)\n",
    "\n",
    "# Plot the training dataset for the two classes #\n",
    "plt.scatter(Xtrain1[:, 0], Xtrain1[:, 1], color='orange', label='Male Class')\n",
    "plt.scatter(Xtrain2[:, 0], Xtrain2[:, 1], color='blue', label='Female Class')\n",
    "plt.title('Decision boundary for the training dataset')\n",
    "plt.xlabel('Height (X1)')\n",
    "plt.ylabel('Weight (X2)')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "2b14cec2ba76430732965a15b26b591c3f84413fa8b3cfe24db625605bfdb2ac"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
